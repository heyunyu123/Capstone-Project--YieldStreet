{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import random\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/heyunyu/Desktop/wd/df_model.csv')\n",
    "note=pd.read_csv(\"/Users/heyunyu/Desktop/wd/original/note_data.csv\")\n",
    "req=pd.read_csv(\"/Users/heyunyu/Desktop/wd/original/investment_requests.csv\")\n",
    "df_full=pd.read_csv(\"/Users/heyunyu/Desktop/wd/classification.csv\")\n",
    "cluster=pd.read_csv(\"/Users/heyunyu/Desktop/wd/cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.drop_duplicates(subset=['anon_investor_account_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(df,cluster[['anon_investor_account_id','cluster']],how='left',on='anon_investor_account_id')\n",
    "df=df.rename(columns={'cluster':'Groups'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df:  all request data with corresponding note information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user-id  relabel  (add a new column user-id 0---3392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label=preprocessing.LabelEncoder()\n",
    "map_user=dict()\n",
    "df['user_id']=label.fit_transform(df['anon_investor_account_id'])\n",
    "## map_user=dict(zip(label.classes_,label.transform(label.classes_)))\n",
    "map_user=dict(zip(label.transform(label.classes_),label.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(map_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_=preprocessing.LabelEncoder()\n",
    "map_user1=dict()\n",
    "df_full['user_id']=label_.fit_transform(df_full['anon_investor_account_id'])\n",
    "## map_user=dict(zip(label.classes_,label.transform(label.classes_)))\n",
    "map_user1=dict(zip(label_.transform(label_.classes_),label_.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "note.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df1=df[df['note_id']!=3074]\n",
    "# df2=df[df['note_id']!=3075]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## payment type: one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pay=preprocessing.LabelEncoder()\n",
    "map_pay=dict()\n",
    "copy=pay.fit_transform(df['schedule_type'])\n",
    "map_pay=dict(zip(pay.classes_,pay.transform(pay.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pay_=preprocessing.OneHotEncoder(sparse=False).fit_transform(copy.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_pay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payment=pd.DataFrame(pay_)\n",
    "payment.columns=['is_I','is_N','is_P']\n",
    "payment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset class: One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl=preprocessing.LabelEncoder()\n",
    "map_cl=dict()\n",
    "copy_cl=cl.fit_transform(df['asset_class'])\n",
    "map_cl=dict(zip(cl.classes_,cl.transform(cl.classes_)))\n",
    "cl_=preprocessing.OneHotEncoder(sparse=False).fit_transform(copy_cl.reshape(-1,1))\n",
    "asset=pd.DataFrame(cl_)\n",
    "asset.columns=['is_com','is_con','is_legal','is_marin','is_real']\n",
    "asset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## also for entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entity=preprocessing.LabelEncoder()\n",
    "map_entity=dict()\n",
    "copy_entity=entity.fit_transform(df['entity_type'])\n",
    "map_entity=dict(zip(entity.classes_,entity.transform(entity.classes_)))\n",
    "entity_=preprocessing.OneHotEncoder(sparse=False).fit_transform(copy_entity.reshape(-1,1))\n",
    "\n",
    "entity_type=pd.DataFrame(entity_)\n",
    "entity_type.columns=['is_BPDN','is_SPVM']\n",
    "entity_type.head()\n",
    "len(entity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## payment type and asset class varibales concat with df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.concat([df,payment],axis=1)\n",
    "df=pd.concat([df,asset],axis=1)\n",
    "df=pd.concat([df,entity_type],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.concat([df,req[['investment_request_waitlisted','investment_request_confirmed']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find all categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat=[]\n",
    "con=[]\n",
    "for v in df.columns:\n",
    "    if len(df[v].value_counts().index)<=15:\n",
    "        cat.append(v)\n",
    "#     else:\n",
    "#         con.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.unique(note['investment_increments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con=['invest_req_amount',\n",
    " 'invest_confirmed_amt',\n",
    " 'offering_size',\n",
    " 'minimum_investment_amount',\n",
    " 'maximum_investment_amount',\n",
    " 'investor_yield',\n",
    " 'term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for element in cat:\n",
    "#     print(element,pd.unique(df[element]))\n",
    "#     print(df[element].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_cols = 4\n",
    "# n_rows = 4\n",
    "# sns.set(style=\"darkgrid\")\n",
    "# for i in range(n_rows):\n",
    "#     fg,ax = plt.subplots(nrows=1,ncols=n_cols,figsize=(18, 6))\n",
    "#     for j in range(n_cols):\n",
    "#         sns.countplot(x=cat[i*n_cols+j], data=df, ax=ax[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_cols=4\n",
    "# n_rows=2\n",
    "\n",
    "# for i in range(n_rows):\n",
    "#     fig,ax=plt.subplots(nrows=1,ncols=n_cols,figsize=(18,8))\n",
    "#     for j in range(n_cols):\n",
    "#         sns.violinplot(y=con[i*n_cols+j],data=df,ax=ax[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def plot_corr(df,size=15):\n",
    "#     corr=df.corr()\n",
    "#     fig,ax=plt.subplots(figsize=(size,size))\n",
    "#     cax=ax.matshow(corr,cmap=plt.get_cmap(\"rainbow\"))\n",
    "#     plt.xticks(range(len(corr.columns)),corr.columns)\n",
    "#     #plt.xticks(df_train.columns) plt.xticks?\n",
    "#     plt.yticks(range(len(corr.columns)),corr.columns)\n",
    "#     plt.colorbar(cax) ## legend\n",
    "# plot_corr(df=d28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select two notes as new offering\n",
    "note_id=3057/3067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first note with id 3057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1=df[df['note_id']==3057][['note_id','offering_size', 'minimum_investment_amount','maximum_investment_amount', 'investment_increments',\n",
    "                   'investor_yield','term', 'is_I', 'is_N', 'is_P','is_BPDN','is_SPVM']].drop_duplicates()\n",
    "df[df['note_id']==3057].asset_class.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second note with id 3067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2=df[df['note_id']==3067][['note_id','offering_size', 'minimum_investment_amount','maximum_investment_amount', 'investment_increments',\n",
    "                   'investor_yield','term', 'is_I', 'is_N', 'is_P','is_BPDN','is_SPVM']].drop_duplicates()\n",
    "df[df['note_id']==3067].asset_class.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function definition\n",
    "using M distance instead of pearson correlation to get similarity\n",
    "\n",
    "The M distance between two points is independent of the measurement unit of original data.  M distance also eliminates the effects of correlation between variables. \n",
    "\n",
    "\n",
    "M distance calculation is established on the basis of the overall sample, because of the covariance matrix,  for example, if the same two samples, in the two different population, finally calculated the M distance between two samples is often not the same, unless the two covariance matrix happened to be the same.\n",
    "\n",
    "In the process of calculating Mdistance, it is required that the total sample number is greater than the dimension of the sample, otherwise the obtained population sample covariance matrix inverse matrix does not exist. \n",
    "\n",
    "due to the two reasons, we combine user history with the wholde note dataset together to calculate M distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get individual history\n",
    "def get_df(df,user_id,asset_class):\n",
    "    d=df[df['user_id']==user_id]\n",
    "    d=d[d['asset_class']==asset_class]\n",
    "    return d\n",
    "\n",
    "## get mahalanobis distance between offerings  \n",
    "def get_dist(df,d,new_note):\n",
    "    df=df[['note_id','offering_size', 'minimum_investment_amount','maximum_investment_amount', 'investment_increments',\n",
    "                       'investor_yield','term', 'is_I', 'is_N', 'is_P','is_BPDN','is_SPVM']]\n",
    "    d_=d[['note_id','offering_size', 'minimum_investment_amount','maximum_investment_amount', 'investment_increments',\n",
    "                       'investor_yield','term', 'is_I', 'is_N', 'is_P','is_BPDN','is_SPVM']]\n",
    "    note=pd.concat([new_note,d_,df],axis=0).drop_duplicates(['note_id']).set_index('note_id')\n",
    "    dist=pdist(note,'mahalanobis')\n",
    "    d_=d_.drop_duplicates(['note_id'])\n",
    "    dist_user=pd.DataFrame(dist).iloc[:d_.shape[0],:]\n",
    "    range1=dist.max()\n",
    "    range0=dist.min()\n",
    "    return dist_user,range1,range0\n",
    " \n",
    "## get predicted request amount\n",
    "def req_amount(d,dist_user):\n",
    "    amount=0\n",
    "    cum=0\n",
    "    if dist_user.shape[0]>=3: \n",
    "        dist_user=dist_user.apply(norm_)\n",
    "        d=d.drop_duplicates(['note_id'])\n",
    "        for i in (range(len(dist_user))):\n",
    "            index=d[['note_id']].iloc[i,:]\n",
    "            sim=1-dist_user.iloc[i,:]\n",
    "            invest=d[d['note_id']==int(index)]['invest_confirmed_amt'].values.sum()\n",
    "            new_invest=invest*sim\n",
    "            amount+=new_invest\n",
    "            cum+=sim\n",
    "        amount=amount/cum\n",
    "        return amount\n",
    "    elif d.shape[0]==0:\n",
    "        return(0)\n",
    "    else:\n",
    "        print(\"Error: Data is too little!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get group history\n",
    "def get_df_group(df_full,df,user_id,asset_class):\n",
    "    label=df_full['Groups'][df_full['user_id']==user_id].reset_index().iloc[0,1]\n",
    "    d=df[df['Groups']==label]\n",
    "    d=d[d['asset_class']==asset_class]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=14.59114254661032\n",
    "r0=0.00\n",
    "def norm_(x):\n",
    "    return ((x-r0)/(r1-r0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d (user history): is generated by function, contains all history of one specified asset class (e.g. Legal) from one specified user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for user with user_id=1890 and asset_class is legal\n",
    "d=get_df(df,user_id=1890,asset_class='LEGL')\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note: concat new note, user history and all note data together\n",
    "because we want to compute the M(mahalanobis) distance for each pair of note, we get a whole data combining previous data together and drop duplicates rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=df[['note_id','offering_size', 'minimum_investment_amount','maximum_investment_amount', 'investment_increments',\n",
    "                       'investor_yield','term', 'is_I', 'is_N', 'is_P','is_BPDN','is_SPVM']]\n",
    "d_=d[['note_id','offering_size', 'minimum_investment_amount','maximum_investment_amount', 'investment_increments',\n",
    "                       'investor_yield','term', 'is_I', 'is_N', 'is_P','is_BPDN','is_SPVM']]\n",
    "note=pd.concat([new1,d_,df_],axis=0).drop_duplicates(['note_id']).set_index('note_id')\n",
    "note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribution of all note normalized distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes=df[['note_id','offering_size', 'minimum_investment_amount','maximum_investment_amount', 'investment_increments',\n",
    "                       'investor_yield','term', 'is_I', 'is_N', 'is_P','is_BPDN','is_SPVM']].drop_duplicates(['note_id']).set_index('note_id')\n",
    "dist=pd.DataFrame(pdist(notes,'mahalanobis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set()\n",
    "dd=1-dist.apply(norm_)\n",
    "sns.distplot(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "using the previously selected two notes and pick two users (user_id=1000/1890)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for investors with investment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=get_df(df,user_id=1000,asset_class='LEGL')\n",
    "u,r1,r0=get_dist(df,d,new1)\n",
    "req_amount(d,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=get_df(df,user_id=1890,asset_class='LEGL')\n",
    "u,r1,r0=get_dist(df,d,new2)\n",
    "req_amount(d,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=get_df(df,user_id=1000,asset_class='REAL')\n",
    "u,r1,r0=get_dist(df,d,new1)\n",
    "req_amount(d,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=get_df(df,1890,'REAL')\n",
    "u,r1,r0=get_dist(df,d,new2)\n",
    "req_amount(d,u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for investors without investment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=get_df_group(df_full,df,200,'LEGL')\n",
    "u,r1,r0=get_dist(df,d,new1)\n",
    "req_amount(d,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "360px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
